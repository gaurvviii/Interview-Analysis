{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports and Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MRQxD6xe6mWN",
        "outputId": "a6039438-d41b-427e-9d78-a9d3c3a1b015"
      },
      "outputs": [],
      "source": [
        "!pip install mediapipe\n",
        "!pip install FER\n",
        "# Download the shape_predictor_68_face_landmarks.dat file\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bunzip2 shape_predictor_68_face_landmarks.dat.bz2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import dlib\n",
        "from imutils import face_utils\n",
        "from scipy.spatial import distance as dist\n",
        "from fer import FER\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZAIZMIG8Nal"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx4eZrTuCuFM"
      },
      "source": [
        "Initialization of Detectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ0uAZRaQBEf",
        "outputId": "d64e6360-dfdf-4e29-c98a-d509b67fc3d7"
      },
      "outputs": [],
      "source": [
        "def initialize_detectors():\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "    fer_detector = FER()\n",
        "    return detector, predictor, fer_detector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiXK7PwAUyBv"
      },
      "source": [
        "Function to Calculate Eye Aspect Ratio (EAR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSSt_YFuQBH_"
      },
      "outputs": [],
      "source": [
        "def eye_aspect_ratio(eye):\n",
        "    A = dist.euclidean(eye[1], eye[5])\n",
        "    B = dist.euclidean(eye[2], eye[4])\n",
        "    C = dist.euclidean(eye[0], eye[3])\n",
        "    ear = (A + B) / (2.0 * C)\n",
        "    return ear\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zHB0Fb4U6si"
      },
      "source": [
        "Function to Calculate Eyeball Movement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4t8DuLaSQBN1"
      },
      "outputs": [],
      "source": [
        "def calculate_eyeball_movement(landmarks):\n",
        "    left_eye = landmarks[42:48]\n",
        "    right_eye = landmarks[36:42]\n",
        "    left_eye_center = left_eye.mean(axis=0).astype(\"int\")\n",
        "    right_eye_center = right_eye.mean(axis=0).astype(\"int\")\n",
        "    left_ear = eye_aspect_ratio(left_eye)\n",
        "    right_ear = eye_aspect_ratio(right_eye)\n",
        "    ear = (left_ear + right_ear) / 2.0\n",
        "    return left_eye_center, right_eye_center, ear\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOtnsj0sU9_6"
      },
      "source": [
        "Function to Process Video and Save Output with Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKF3WrelTWEV"
      },
      "outputs": [],
      "source": [
        "def main(video_path):\n",
        "    # Initialize detectors\n",
        "    detector, predictor, fer_detector = initialize_detectors()\n",
        "\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get video details\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Define the codec and create a VideoWriter object to save the output video\n",
        "    output_path = video_path.split('.')[0] + '_output.mp4'\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Initialize variables\n",
        "    movement_counts = []\n",
        "    blink_counts = 0\n",
        "    emotion_counts = {'angry': 0, 'disgust': 0, 'fear': 0, 'happy': 0, 'sad': 0, 'surprise': 0, 'neutral': 0}\n",
        "    prev_left_eye_center = None\n",
        "    prev_right_eye_center = None\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        rects = detector(gray, 0)\n",
        "\n",
        "        for rect in rects:\n",
        "            shape = predictor(gray, rect)\n",
        "            shape = face_utils.shape_to_np(shape)\n",
        "            left_eye_center, right_eye_center, ear = calculate_eyeball_movement(shape)\n",
        "\n",
        "            if prev_left_eye_center is not None and prev_right_eye_center is not None:\n",
        "                left_movement = dist.euclidean(prev_left_eye_center, left_eye_center)\n",
        "                right_movement = dist.euclidean(prev_right_eye_center, right_eye_center)\n",
        "                movement_counts.append(left_movement + right_movement)\n",
        "\n",
        "                if ear < 0.21:  # Threshold for blinking\n",
        "                    blink_counts += 1\n",
        "\n",
        "                # Draw eye centers and EAR on the frame\n",
        "                cv2.circle(frame, tuple(left_eye_center), 2, (0, 255, 0), -1)\n",
        "                cv2.circle(frame, tuple(right_eye_center), 2, (0, 255, 0), -1)\n",
        "                cv2.putText(frame, f\"EAR: {ear:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "            prev_left_eye_center = left_eye_center\n",
        "            prev_right_eye_center = right_eye_center\n",
        "\n",
        "        # Emotion detection\n",
        "        result = fer_detector.detect_emotions(frame)\n",
        "        for face in result:\n",
        "            emotions = face['emotions']\n",
        "            top_emotion = max(emotions, key=emotions.get)\n",
        "            emotion_counts[top_emotion] += 1\n",
        "            cv2.putText(frame, f\"Emotion: {top_emotion}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "\n",
        "        # Calculate average movement and blink count\n",
        "        avg_movement_rate = np.mean(movement_counts) if movement_counts else 0\n",
        "\n",
        "        # Evaluate the expression-based description\n",
        "        total_frames = sum(emotion_counts.values())\n",
        "        emotion_percentages = {emotion: (count / total_frames) * 100 for emotion, count in emotion_counts.items()} if total_frames > 0 else {emotion: 0 for emotion in emotion_counts}\n",
        "\n",
        "        dominant_emotion = max(emotion_percentages, key=emotion_percentages.get)\n",
        "        dominant_emotion_percentage = emotion_percentages[dominant_emotion]\n",
        "\n",
        "        # Generate detailed description\n",
        "        description = \"\"\n",
        "        confidence_score = 8  # Default confidence score\n",
        "\n",
        "        if dominant_emotion in ['fear', 'disgust']:\n",
        "            description = (\n",
        "                f\"The candidate appears quite uneasy with a dominant emotional state of {dominant_emotion} \"\n",
        "                f\"at {dominant_emotion_percentage:.2f}%. Additionally, there is some evidence of nervousness \"\n",
        "                f\"indicated by eye movements and blinking. Overall, the candidate's demeanor suggests a higher \"\n",
        "                f\"level of anxiety.\"\n",
        "            )\n",
        "            confidence_score -= 2\n",
        "        elif dominant_emotion in ['happy', 'neutral']:\n",
        "            description = (\n",
        "                f\"The candidate seems relaxed or positive with a dominant emotional state of {dominant_emotion} \"\n",
        "                f\"at {dominant_emotion_percentage:.2f}%. The eye movement and blinking are within normal ranges, \"\n",
        "                f\"indicating that the candidate is calm and composed throughout the video.\"\n",
        "            )\n",
        "            confidence_score += 1\n",
        "        else:\n",
        "            description = (\n",
        "                f\"The candidate shows a mixed emotional state with no dominant emotion. Eye movement and blink rate \"\n",
        "                f\"are moderate, suggesting that while the candidate might not be extremely anxious, there are \"\n",
        "                f\"slight signs of nervousness. The overall demeanor is neutral.\"\n",
        "            )\n",
        "\n",
        "        if avg_movement_rate > 2 or blink_counts > 20:\n",
        "            description += (\n",
        "                \" The eye movement and blink count suggest some level of nervousness, adding to the overall \"\n",
        "                \"impression of anxiety or unease.\"\n",
        "            )\n",
        "            confidence_score -= 2\n",
        "\n",
        "        # Ensure confidence score is within 0-10 range\n",
        "        confidence_score = max(0, min(10, confidence_score))\n",
        "\n",
        "        # Display calculated parameters\n",
        "        cv2.putText(frame, f\"Avg Movement Rate: {avg_movement_rate:.2f}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "        cv2.putText(frame, f\"Blink Count: {blink_counts}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "        cv2.putText(frame, f\"Dominant Emotion: {dominant_emotion.capitalize()} ({dominant_emotion_percentage:.2f}%)\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "        cv2.putText(frame, f\"Overall Description: {description}\", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "        cv2.putText(frame, f\"Confidence Score: {confidence_score}/10\", (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        # Write the annotated frame to the output video\n",
        "        out.write(frame)\n",
        "\n",
        "    # Release the video capture and writer objects\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    # Output results\n",
        "    print(f\"Output video saved to {output_path}\")\n",
        "    print(f\"Average Eye Movement Rate: {avg_movement_rate:.2f}\")\n",
        "    print(f\"Blink Count: {blink_counts}\")\n",
        "    print(f\"Emotion Counts: {emotion_counts}\")\n",
        "    print(f\"Overall Description: {description}\")\n",
        "    print(f\"Confidence Score: {confidence_score}/10\")\n",
        "\n",
        "    return avg_movement_rate, blink_counts, emotion_counts, confidence_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE5U5EHyVE50"
      },
      "source": [
        "Example Usage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1hIXDAxQBZl",
        "outputId": "7341c340-3447-4ede-c8d3-38d6bb332aba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output video saved to /content/confident_output.mp4\n",
            "Average Eye Movement Rate: 2.33\n",
            "Blink Count: 5\n",
            "Emotion Counts: {'angry': 1, 'disgust': 4, 'fear': 1, 'happy': 112, 'sad': 46, 'surprise': 17, 'neutral': 141}\n",
            "Overall Description: The candidate seems relaxed or positive with a dominant emotional state of neutral at 43.79%. The eye movement and blinking are within normal ranges, indicating that the candidate is calm and composed throughout the video. The eye movement and blink count suggest some level of nervousness, adding to the overall impression of anxiety or unease.\n",
            "Confidence Score: 7/10\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Example usage with a sample video path\n",
        "    video_path = \"/content/confident.mp4\"\n",
        "    main(video_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoxzguQHVavE",
        "outputId": "efbf198b-28bf-4672-cdbf-7d503a3993fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JDSYUnTwQRNhS4ok9vvp_uPKXMyByAoc\n",
            "To: /content/suresh_calm.mp4\n",
            "100% 2.32M/2.32M [00:00<00:00, 182MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LwHhDOsYBntDIOCXAV-uLFklk7GLA1kg\n",
            "To: /content/powerbi_less_conf.mp4\n",
            "100% 3.89M/3.89M [00:00<00:00, 185MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XbgwqznZY-MIJoPNNFNSx1VcLO2Rw1PV\n",
            "To: /content/powerbi_good.mp4\n",
            "100% 4.43M/4.43M [00:00<00:00, 70.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zsWgEuyzCa5jopu7PW0nyQ5HaYe35pMM\n",
            "To: /content/nikhilPoor.mp4\n",
            "100% 4.32M/4.32M [00:00<00:00, 97.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16wuy2oXLspfq_TSFKZknaguVhdk95K2q\n",
            "To: /content/nikhilGood.mp4\n",
            "100% 3.79M/3.79M [00:00<00:00, 129MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vAVqH7IHfVb2WUTMrzySlHnTwkjChAM2\n",
            "To: /content/nikhilBetter.mp4\n",
            "100% 4.29M/4.29M [00:00<00:00, 92.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1JDSYUnTwQRNhS4ok9vvp_uPKXMyByAoc\n",
        "!gdown 1LwHhDOsYBntDIOCXAV-uLFklk7GLA1kg\n",
        "!gdown 1XbgwqznZY-MIJoPNNFNSx1VcLO2Rw1PV\n",
        "!gdown 1zsWgEuyzCa5jopu7PW0nyQ5HaYe35pMM\n",
        "!gdown 16wuy2oXLspfq_TSFKZknaguVhdk95K2q\n",
        "!gdown 1vAVqH7IHfVb2WUTMrzySlHnTwkjChAM2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grWDs7hIQBc7",
        "outputId": "294d8282-c11e-43d5-edc5-b28e8d133768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output video saved to /content/nikhilGood_output.mp4\n",
            "Average Eye Movement Rate: 886.52\n",
            "Blink Count: 19\n",
            "Emotion Counts: {'angry': 94, 'disgust': 0, 'fear': 0, 'happy': 3, 'sad': 11, 'surprise': 2, 'neutral': 438}\n",
            "Overall Description: The candidate seems relaxed or positive with a dominant emotional state of neutral at 79.93%. The eye movement and blinking are within normal ranges, indicating that the candidate is calm and composed throughout the video. The eye movement and blink count suggest some level of nervousness, adding to the overall impression of anxiety or unease.\n",
            "Confidence Score: 7/10\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Example usage with a sample video path\n",
        "    video_path = \"/content/nikhilGood.mp4\"\n",
        "    main(video_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
